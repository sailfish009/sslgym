{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q3k-vKd0c8Uk"
   },
   "source": [
    "# üì¶ Packages and Basic Setup\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "QoNTJN31iTgb"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -U rich tf-models-official\n",
    "\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "from rich import print\n",
    "import tensorflow_models as tfm\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from rich.progress import track\n",
    "from tensorflow.python.ops.numpy_ops import np_config\n",
    "\n",
    "from typing import Callable, Tuple, Any, List\n",
    "\n",
    "# Experimental options\n",
    "options = tf.data.Options()\n",
    "options.experimental_optimization.noop_elimination = True\n",
    "options.experimental_optimization.apply_default_optimizations = True\n",
    "options.experimental_deterministic = False\n",
    "options.threading.max_intra_op_parallelism = 1\n",
    "np_config.enable_numpy_behavior()\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "x0ak7lsXgKf5",
    "outputId": "cb94a80e-f87d-40c6-e268-3262221b472f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Random seed set as <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Random seed set as \u001b[1;36m42\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# @title ‚öô Configuration\n",
    "GLOBAL_SEED = 42  # @param {type: \"number\"}\n",
    "NUM_VIEWS = 2  # @param {type: \"number\"}\n",
    "NUM_EPOCHS = 10  # @param {type: \"number\"}\n",
    "BATCH_SIZE = 32  # @param {type: \"number\"}\n",
    "MLP_UNITS = 8192  # @param {type: \"number\"}\n",
    "INVAR_COEFF = 25.0  # @param {type: \"number\"}\n",
    "VAR_COEFF = 25.0  # @param {type: \"number\"}\n",
    "COV_COEFF = 1.0  # @param {type: \"number\"}\n",
    "DECAY_STEPS = 1000  # @param {type: \"number\"}\n",
    "WEIGHT_DECAY = 1e-6  # @param {type: \"number\"}\n",
    "BASE_LR = 0.2  # @param {type: \"number\"}\n",
    "\n",
    "\n",
    "# ============ Random Seed ============\n",
    "def seed_everything(seed=GLOBAL_SEED):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    tf.experimental.numpy.random.seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    os.environ[\"TF_CUDNN_DETERMINISTIC\"] = \"1\"\n",
    "    os.environ[\"TF_DETERMINISTIC_OPS\"] = \"1\"\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    print(f\"Random seed set as {seed}\")\n",
    "\n",
    "\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PNagRfSfdAmO"
   },
   "source": [
    "# üÜò Utility Classes and Functions\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "B9o8vLp4w69C"
   },
   "outputs": [],
   "source": [
    "def off_diagonal(x: tf.Tensor) -> tf.Tensor:\n",
    "    n, m = x.shape[0], x.shape[1]\n",
    "    assert n == m, f\"Not a square tensor, dimensions found: {n} and {m}\"\n",
    "\n",
    "    flattened_tensor = tf.reshape(x, [-1])[:-1]\n",
    "    elements = tf.reshape(flattened_tensor, [n - 1, n + 1])[:, 1:]\n",
    "    return tf.reshape(elements, [-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wGDPpTX_dCl1"
   },
   "source": [
    "## üññ Utilites for Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "zvPO2q_uj_f7"
   },
   "outputs": [],
   "source": [
    "GAUSSIAN_P = [1.0, 0.1]\n",
    "SOLARIZE_P = [0.0, 0.2]\n",
    "\n",
    "def shuffle_zipped_output(a: Any, b: Any) -> Tuple[Any]:\n",
    "    \"\"\"Shuffle the given inputs\"\"\"\n",
    "    listify = [a,b]\n",
    "    random.shuffle(listify)\n",
    "    return listify[0], listify[1]\n",
    "\n",
    "@tf.function\n",
    "def scale_image(image: tf.Tensor, label: tf.Tensor) -> Tuple[tf.Tensor]:\n",
    "    \"\"\"Convert all images to float32\"\"\"\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    return (image, label)\n",
    "\n",
    "@tf.function\n",
    "def gaussian_blur(image: tf.Tensor, kernel_size:int=23, padding: str='SAME') -> tf.Tensor:\n",
    "    \"\"\"\n",
    "    Randomly apply Gaussian Blur to the input image\n",
    "    \n",
    "    Reference: https://github.com/google-research/simclr/blob/master/data_util.py\n",
    "    \"\"\"\n",
    "\n",
    "    sigma = tf.random.uniform((1,))* 1.9 + 0.1\n",
    "    radius = tf.cast(kernel_size / 2, tf.int32)\n",
    "    kernel_size = radius * 2 + 1\n",
    "    x = tf.cast(tf.range(-radius, radius + 1), tf.float32)\n",
    "    blur_filter = tf.exp(\n",
    "        -tf.pow(x, 2.0) / (2.0 * tf.pow(tf.cast(sigma, tf.float32), 2.0)))\n",
    "    blur_filter /= tf.reduce_sum(blur_filter)\n",
    "\n",
    "    # One vertical and one horizontal filter.\n",
    "    blur_v = tf.reshape(blur_filter, [kernel_size, 1, 1, 1])\n",
    "    blur_h = tf.reshape(blur_filter, [1, kernel_size, 1, 1])\n",
    "    num_channels = tf.shape(image)[-1]\n",
    "    blur_h = tf.tile(blur_h, [1, 1, num_channels, 1])\n",
    "    blur_v = tf.tile(blur_v, [1, 1, num_channels, 1])\n",
    "    expand_batch_dim = image.shape.ndims == 3\n",
    "    if expand_batch_dim:\n",
    "      image = tf.expand_dims(image, axis=0)\n",
    "    blurred = tf.nn.depthwise_conv2d(\n",
    "        image, blur_h, strides=[1, 1, 1, 1], padding=padding)\n",
    "    blurred = tf.nn.depthwise_conv2d(\n",
    "        blurred, blur_v, strides=[1, 1, 1, 1], padding=padding)\n",
    "    if expand_batch_dim:\n",
    "      blurred = tf.squeeze(blurred, axis=0)\n",
    "    return blurred\n",
    "\n",
    "@tf.function\n",
    "def color_jitter(image: tf.Tensor, s: float = 0.5) -> tf.Tensor:\n",
    "    \"\"\"Randomly apply Color Jittering to the input image\"\"\"\n",
    "    x = tf.image.random_brightness(image, max_delta=0.8*s)\n",
    "    x = tf.image.random_contrast(x, lower=1-0.8*s, upper=1+0.8*s)\n",
    "    x = tf.image.random_saturation(x, lower=1-0.8*s, upper=1+0.8*s)\n",
    "    x = tf.image.random_hue(x, max_delta=0.2*s)\n",
    "    x = tf.clip_by_value(x, 0, 1)\n",
    "    return x\n",
    "\n",
    "@tf.function\n",
    "def solarize(image: tf.Tensor, threshold: int = 128) -> tf.Tensor:\n",
    "    \"\"\"Solarize the input image\"\"\"\n",
    "    return tf.where(image < threshold, image, 255 - image)\n",
    "\n",
    "@tf.function\n",
    "def color_drop(image: tf.Tensor) -> tf.Tensor:\n",
    "    \"\"\"Randomly convert the input image to GrayScale\"\"\"\n",
    "    image = tf.image.rgb_to_grayscale(image)\n",
    "    image = tf.tile(image, [1, 1, 3])\n",
    "    return image\n",
    "\n",
    "@tf.function\n",
    "def random_apply(func: Callable, x: tf.Tensor, p: float) -> tf.Tensor:\n",
    "    \"\"\"Randomly apply the desired func to the input image\"\"\"\n",
    "    return tf.cond(\n",
    "        tf.less(tf.random.uniform([], minval=0, maxval=1, dtype=tf.float32),\n",
    "                tf.cast(p, tf.float32)),\n",
    "        lambda: func(x),\n",
    "        lambda: x)\n",
    "\n",
    "@tf.function\n",
    "def custom_augment(image: tf.Tensor, label: tf.Tensor, gaussian_p: float = 0.1, solarize_p: float = 0.0) -> Tuple[tf.Tensor]:       \n",
    "    \"\"\"Container function to apply all custom augmentations\"\"\"\n",
    "    # Random flips\n",
    "    image = random_apply(tf.image.flip_left_right, image, p=0.5)\n",
    "    # Randomly apply transformation (color distortions) with probability p.\n",
    "    image = random_apply(color_jitter, image, p=0.8)\n",
    "    # Randomly apply grayscale\n",
    "    image = random_apply(color_drop, image, p=0.2)\n",
    "    # Randomly apply gausian blur\n",
    "    image = random_apply(gaussian_blur, image, p=gaussian_p)\n",
    "    # Randomly apply solarization\n",
    "    image = random_apply(solarize, image, p=solarize_p)\n",
    "\n",
    "    return (image, label)\n",
    "\n",
    "@tf.function\n",
    "def random_resize_crop(image: tf.Tensor, label: tf.Tensor, gaussian_p: float = 0.1, solarize_p: float = 0.0, crop_size:int = 224) -> Tuple[tf.Tensor]:\n",
    "    \"\"\"Randomly Resize and Augment Crops\"\"\"\n",
    "    # scale the pixel values\n",
    "    image, label = scale_image(image , label)\n",
    "    # image resizing\n",
    "    image_shape = 260\n",
    "    image = tf.image.resize(image, (image_shape, image_shape))\n",
    "    # get the crop from the image\n",
    "    crop = tf.image.random_crop(image, (crop_size,crop_size,3))\n",
    "    crop_resize = tf.image.resize(crop, (crop_size, crop_size))\n",
    "    # color distortions\n",
    "    distored_image, label = custom_augment(crop_resize, label, gaussian_p)\n",
    "    return distored_image, label "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-TyhdhWEfuoI"
   },
   "source": [
    "# üíø The Dataset\n",
    "\n",
    "---\n",
    "\n",
    "For the purposes of this example, we use the TF Flowers dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jbKVJJKvj21x",
    "outputId": "7c1f2e4a-5916-44b9-d02d-5543eddedeab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset 218.21 MiB (download: 218.21 MiB, generated: 221.83 MiB, total: 440.05 MiB) to ~/tensorflow_datasets/tf_flowers/3.0.1...\n",
      "Dataset tf_flowers downloaded and prepared to ~/tensorflow_datasets/tf_flowers/3.0.1. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "tfds.disable_progress_bar()\n",
    "\n",
    "# Gather Flowers dataset\n",
    "train_ds, validation_ds = tfds.load(\n",
    "    \"tf_flowers\",\n",
    "    split=[\"train[:85%]\", \"train[85%:]\"],\n",
    "    as_supervised=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bzaJxSEof6_M"
   },
   "source": [
    "## üññ Data Augmentation Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ctHaiHHEPuVB",
    "outputId": "b6206171-11d9-4c9e-e19a-2fe8463579f8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    }
   ],
   "source": [
    "# We create a Tuple because we have two loaders corresponding to each view\n",
    "trainloaders = tuple()\n",
    "\n",
    "for i in range(NUM_VIEWS):\n",
    "  trainloader = (\n",
    "      train_ds\n",
    "      .shuffle(1024)\n",
    "      .map(lambda x, y: random_resize_crop(x, y, GAUSSIAN_P[i], SOLARIZE_P[i]), num_parallel_calls=AUTOTUNE)\n",
    "  )\n",
    "  trainloader = trainloader.with_options(options)\n",
    "  trainloaders+=(trainloader,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-8zt-j3Zf-la"
   },
   "source": [
    "## ‚öôÔ∏è Dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "zJp3ViRVQCwS"
   },
   "outputs": [],
   "source": [
    "# zip both the dataloaders together\n",
    "trainloader = tf.data.Dataset.zip(trainloaders)\n",
    "\n",
    "# final trainloader to be used for training\n",
    "trainloader = (\n",
    "    trainloader\n",
    "    .batch(BATCH_SIZE * strategy.num_replicas_in_sync)\n",
    "    .map(shuffle_zipped_output, num_parallel_calls=AUTOTUNE)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VQTV9RotiRCW"
   },
   "source": [
    "# ‚úçÔ∏è Model Architecture & Training\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3IsyuaYYiTka"
   },
   "source": [
    "## üè† Building the network\n",
    "![](https://github.com/facebookresearch/vicreg/blob/main/.github/vicreg_archi_full.jpg?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "e3yk3MH6ifAc"
   },
   "outputs": [],
   "source": [
    "class VICReg(tf.keras.Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_units: int,\n",
    "        invar_coeff: float,\n",
    "        var_coeff: float,\n",
    "        cov_coeff: float,\n",
    "        **kwargs\n",
    "    ) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.num_units = num_units\n",
    "        self.invar_coeff = invar_coeff\n",
    "        self.var_coeff = var_coeff\n",
    "        self.cov_coeff = cov_coeff\n",
    "\n",
    "        self.encoder = self.build_encoder()\n",
    "        self.expander = self.build_expander(self.num_units)\n",
    "\n",
    "        self.loss_tracker = tf.keras.metrics.Mean(name=\"vicreg_loss\")\n",
    "        self.invarloss_tracker = tf.keras.metrics.Mean(name=\"invariance_loss\")\n",
    "        self.varloss_tracker = tf.keras.metrics.Mean(name=\"variance_loss\")\n",
    "        self.covloss_tracker = tf.keras.metrics.Mean(name=\"covariance_loss\")\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\n",
    "            \"invar_coeff\": self.invar_coeff,\n",
    "            \"var_coeff\": self.var_coeff,\n",
    "            \"cov_coeff\": self.cov_coeff,\n",
    "            \"num_units\": self.num_units,\n",
    "        }\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.loss_tracker,\n",
    "            self.invarloss_tracker,\n",
    "            self.varloss_tracker,\n",
    "            self.covloss_tracker,\n",
    "        ]\n",
    "\n",
    "    def build_encoder(self):\n",
    "        encoder_input = tf.keras.layers.Input((None, None, 3))\n",
    "        base_model = tf.keras.applications.ResNet50(\n",
    "            include_top=False, weights=None, input_shape=(None, None, 3)\n",
    "        )\n",
    "        base_model.trainable = True\n",
    "        representations = base_model(encoder_input, training=True)\n",
    "        encoder_output = tf.keras.layers.GlobalAveragePooling2D()(representations)\n",
    "        encoder = tf.keras.models.Model(\n",
    "            inputs=encoder_input, outputs=encoder_output, name=\"encoder\"\n",
    "        )\n",
    "        return encoder\n",
    "\n",
    "    def build_expander(self, num_units: int):\n",
    "        expander_input = tf.keras.layers.Input((2048,))\n",
    "\n",
    "        projection_1 = tf.keras.layers.Dense(num_units)(expander_input)\n",
    "        projection_1 = tf.keras.layers.BatchNormalization()(projection_1)\n",
    "        projection_1 = tf.keras.layers.Activation(\"relu\")(projection_1)\n",
    "\n",
    "        projection_2 = tf.keras.layers.Dense(num_units)(projection_1)\n",
    "        projection_2 = tf.keras.layers.BatchNormalization()(projection_2)\n",
    "        projection_2 = tf.keras.layers.Activation(\"relu\")(projection_2)\n",
    "\n",
    "        expander_output = tf.keras.layers.Dense(num_units)(projection_2)\n",
    "\n",
    "        expander = tf.keras.models.Model(\n",
    "            inputs=expander_input, outputs=expander_output, name=\"expander\"\n",
    "        )\n",
    "\n",
    "        return expander\n",
    "\n",
    "    def train_step(self, images):\n",
    "        x, x_prime = images[0][0], images[1][0]\n",
    "        inputs = [x, x_prime]\n",
    "        batch_size = inputs[0][0].shape[0]\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Get Representations (through encoder)\n",
    "            y = self.encoder(x)\n",
    "            y_prime = self.encoder(x_prime)\n",
    "\n",
    "            # Get Embeddings (through expander)\n",
    "            z = self.expander(y)\n",
    "            z_prime = self.expander(y_prime)\n",
    "\n",
    "            # Calculate the Representation (Invariance) Loss\n",
    "            invar_loss = tf.keras.metrics.mean_squared_error(z, z_prime)\n",
    "\n",
    "            # Calculate var. and std. dev. of embeddings\n",
    "            z = z - tf.reduce_mean(z, axis=0)\n",
    "            z_prime = z_prime - tf.reduce_mean(z_prime, axis=0)\n",
    "            std_z = tf.sqrt(tf.math.reduce_variance(z, axis=0) + 0.0001)\n",
    "            std_z_prime = tf.sqrt(tf.math.reduce_variance(z_prime, axis=0) + 0.0001)\n",
    "\n",
    "            # Calculate the Variance Loss (Hinge Function)\n",
    "            var_loss = (\n",
    "                tf.reduce_mean(tf.nn.relu(1 - std_z)) / 2\n",
    "                + tf.reduce_mean(tf.nn.relu(1 - std_z_prime)) / 2\n",
    "            )\n",
    "\n",
    "            # Get Covariance Matrix\n",
    "            cov_z = (z.T @ z) / (batch_size - 1)\n",
    "            cov_z_prime = (z_prime.T @ z_prime) / (batch_size - 1)\n",
    "\n",
    "            # Calculate the Covariance Loss\n",
    "            cov_loss_z = tf.divide(tf.reduce_sum(tf.pow(off_diagonal(cov_z), 2)), 8192)\n",
    "            cov_loss_z_prime = tf.divide(\n",
    "                tf.reduce_sum(tf.pow(off_diagonal(cov_z_prime), 2)), 8192\n",
    "            )\n",
    "            cov_loss = cov_loss_z + cov_loss_z_prime\n",
    "\n",
    "            # Weighted Avg. of Invariance, Variance and Covariance Loss\n",
    "            loss = (\n",
    "                self.invar_coeff * invar_loss\n",
    "                + self.var_coeff * var_loss\n",
    "                + self.cov_coeff * cov_loss\n",
    "            )\n",
    "\n",
    "        # Compute gradients\n",
    "        variables = self.encoder.trainable_variables + self.expander.trainable_variables\n",
    "        gradients = tape.gradient(loss, variables)\n",
    "        # Update weights\n",
    "        self.optimizer.apply_gradients(zip(gradients, variables))\n",
    "        # Compute our own metrics\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        self.invarloss_tracker.update_state(invar_loss)\n",
    "        self.varloss_tracker.update_state(var_loss)\n",
    "        self.covloss_tracker.update_state(cov_loss)\n",
    "        # Return a dict mapping metric names to current value\n",
    "        return {\n",
    "            \"loss\": self.loss_tracker.result(),\n",
    "            \"invariance_loss\": self.invarloss_tracker.result(),\n",
    "            \"variance_loss\": self.varloss_tracker.result(),\n",
    "            \"covariance_loss\": self.covloss_tracker.result(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5jX8kkEP59YB"
   },
   "source": [
    "## üèÉ Train !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E5VIi6z3z3nU"
   },
   "outputs": [],
   "source": [
    "# The training protocol for VICReg follows those of BYOL and Barlow Twins,\n",
    "# i.e. the use of LARS which is adaptive algorithm meant for large batch training\n",
    "lr_decayed_fn = tf.keras.optimizers.schedules.CosineDecay(\n",
    "    initial_learning_rate=BASE_LR, decay_steps=DECAY_STEPS\n",
    ")\n",
    "opt = tfm.optimization.lars_optimizer.LARS(\n",
    "    learning_rate=lr_decayed_fn, weight_decay_rate=WEIGHT_DECAY\n",
    ")\n",
    "\n",
    "with strategy.scope():\n",
    "    model = VICReg(\n",
    "        num_units=MLP_UNITS,\n",
    "        invar_coeff=INVAR_COEFF,\n",
    "        var_coeff=VAR_COEFF,\n",
    "        cov_coeff=COV_COEFF,\n",
    "    )\n",
    "    model.compile(optimizer=opt)\n",
    "model.fit(trainloader, epochs=3)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
