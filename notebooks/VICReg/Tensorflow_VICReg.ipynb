{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3k-vKd0c8Uk"
      },
      "source": [
        "# üì¶ Packages and Basic Setup\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QoNTJN31iTgb"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install -U rich tf-models-official\n",
        "\n",
        "import random\n",
        "import os\n",
        "import numpy as np\n",
        "from rich import print\n",
        "import tensorflow_models as tfm\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from rich.progress import track\n",
        "from tensorflow.python.ops.numpy_ops import np_config\n",
        "\n",
        "from typing import Callable, Tuple, Any, List\n",
        "\n",
        "# Experimental options\n",
        "options = tf.data.Options()\n",
        "options.experimental_optimization.noop_elimination = True\n",
        "options.experimental_optimization.apply_default_optimizations = True\n",
        "options.experimental_deterministic = False\n",
        "options.threading.max_intra_op_parallelism = 1\n",
        "np_config.enable_numpy_behavior()\n",
        "\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "strategy = tf.distribute.MirroredStrategy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0ak7lsXgKf5"
      },
      "outputs": [],
      "source": [
        "# @title ‚öô Configuration\n",
        "GLOBAL_SEED = 42  # @param {type: \"number\"}\n",
        "NUM_VIEWS = 2  # @param {type: \"number\"}\n",
        "NUM_TRAINING_EPOCHS = 10  # @param {type: \"number\"}\n",
        "NUM_EVAL_EPOCHS = 100  # @param {type: \"number\"}\n",
        "TRAIN_BATCH_SIZE = 32  # @param {type: \"number\"}\n",
        "EVAL_BATCH_SIZE = 256  # @param {type: \"number\"}\n",
        "MLP_UNITS = 8192  # @param {type: \"number\"}\n",
        "INVAR_COEFF = 25.0  # @param {type: \"number\"}\n",
        "VAR_COEFF = 25.0  # @param {type: \"number\"}\n",
        "COV_COEFF = 1.0  # @param {type: \"number\"}\n",
        "DECAY_STEPS = 1000  # @param {type: \"number\"}\n",
        "WEIGHT_DECAY = 1e-6  # @param {type: \"number\"}\n",
        "BASE_LR = 0.2  # @param {type: \"number\"}\n",
        "EVAL_LR = 0.02  # @param {type: \"number\"}\n",
        "\n",
        "\n",
        "# ============ Random Seed ============\n",
        "def seed_everything(seed=GLOBAL_SEED):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    tf.experimental.numpy.random.seed(seed)\n",
        "    # When running on the CuDNN backend, two further options must be set\n",
        "    os.environ[\"TF_CUDNN_DETERMINISTIC\"] = \"1\"\n",
        "    os.environ[\"TF_DETERMINISTIC_OPS\"] = \"1\"\n",
        "    # Set a fixed value for the hash seed\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    print(f\"Random seed set as {seed}\")\n",
        "\n",
        "\n",
        "seed_everything()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNagRfSfdAmO"
      },
      "source": [
        "# üÜò Utility Classes and Functions\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9o8vLp4w69C"
      },
      "outputs": [],
      "source": [
        "def off_diagonal(x: tf.Tensor) -> tf.Tensor:\n",
        "    n, m = x.shape[0], x.shape[1]\n",
        "    assert n == m, f\"Not a square tensor, dimensions found: {n} and {m}\"\n",
        "\n",
        "    flattened_tensor = tf.reshape(x, [-1])[:-1]\n",
        "    elements = tf.reshape(flattened_tensor, [n - 1, n + 1])[:, 1:]\n",
        "    return tf.reshape(elements, [-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGDPpTX_dCl1"
      },
      "source": [
        "## üññ Utilites for Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zvPO2q_uj_f7"
      },
      "outputs": [],
      "source": [
        "GAUSSIAN_P = [1.0, 0.1]\n",
        "SOLARIZE_P = [0.0, 0.2]\n",
        "\n",
        "def shuffle_zipped_output(a: Any, b: Any) -> Tuple[Any]:\n",
        "    \"\"\"Shuffle the given inputs\"\"\"\n",
        "    listify = [a,b]\n",
        "    random.shuffle(listify)\n",
        "    return listify[0], listify[1]\n",
        "\n",
        "@tf.function\n",
        "def scale_image(image: tf.Tensor, label: tf.Tensor) -> Tuple[tf.Tensor]:\n",
        "    \"\"\"Convert all images to float32\"\"\"\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "    return (image, label)\n",
        "\n",
        "@tf.function\n",
        "def gaussian_blur(image: tf.Tensor, kernel_size:int=23, padding: str='SAME') -> tf.Tensor:\n",
        "    \"\"\"\n",
        "    Randomly apply Gaussian Blur to the input image\n",
        "    \n",
        "    Reference: https://github.com/google-research/simclr/blob/master/data_util.py\n",
        "    \"\"\"\n",
        "\n",
        "    sigma = tf.random.uniform((1,))* 1.9 + 0.1\n",
        "    radius = tf.cast(kernel_size / 2, tf.int32)\n",
        "    kernel_size = radius * 2 + 1\n",
        "    x = tf.cast(tf.range(-radius, radius + 1), tf.float32)\n",
        "    blur_filter = tf.exp(\n",
        "        -tf.pow(x, 2.0) / (2.0 * tf.pow(tf.cast(sigma, tf.float32), 2.0)))\n",
        "    blur_filter /= tf.reduce_sum(blur_filter)\n",
        "\n",
        "    # One vertical and one horizontal filter.\n",
        "    blur_v = tf.reshape(blur_filter, [kernel_size, 1, 1, 1])\n",
        "    blur_h = tf.reshape(blur_filter, [1, kernel_size, 1, 1])\n",
        "    num_channels = tf.shape(image)[-1]\n",
        "    blur_h = tf.tile(blur_h, [1, 1, num_channels, 1])\n",
        "    blur_v = tf.tile(blur_v, [1, 1, num_channels, 1])\n",
        "    expand_batch_dim = image.shape.ndims == 3\n",
        "    if expand_batch_dim:\n",
        "      image = tf.expand_dims(image, axis=0)\n",
        "    blurred = tf.nn.depthwise_conv2d(\n",
        "        image, blur_h, strides=[1, 1, 1, 1], padding=padding)\n",
        "    blurred = tf.nn.depthwise_conv2d(\n",
        "        blurred, blur_v, strides=[1, 1, 1, 1], padding=padding)\n",
        "    if expand_batch_dim:\n",
        "      blurred = tf.squeeze(blurred, axis=0)\n",
        "    return blurred\n",
        "\n",
        "@tf.function\n",
        "def color_jitter(image: tf.Tensor, s: float = 0.5) -> tf.Tensor:\n",
        "    \"\"\"Randomly apply Color Jittering to the input image\"\"\"\n",
        "    x = tf.image.random_brightness(image, max_delta=0.8*s)\n",
        "    x = tf.image.random_contrast(x, lower=1-0.8*s, upper=1+0.8*s)\n",
        "    x = tf.image.random_saturation(x, lower=1-0.8*s, upper=1+0.8*s)\n",
        "    x = tf.image.random_hue(x, max_delta=0.2*s)\n",
        "    x = tf.clip_by_value(x, 0, 1)\n",
        "    return x\n",
        "\n",
        "@tf.function\n",
        "def solarize(image: tf.Tensor, threshold: int = 128) -> tf.Tensor:\n",
        "    \"\"\"Solarize the input image\"\"\"\n",
        "    return tf.where(image < threshold, image, 255 - image)\n",
        "\n",
        "@tf.function\n",
        "def color_drop(image: tf.Tensor) -> tf.Tensor:\n",
        "    \"\"\"Randomly convert the input image to GrayScale\"\"\"\n",
        "    image = tf.image.rgb_to_grayscale(image)\n",
        "    image = tf.tile(image, [1, 1, 3])\n",
        "    return image\n",
        "\n",
        "@tf.function\n",
        "def random_apply(func: Callable, x: tf.Tensor, p: float) -> tf.Tensor:\n",
        "    \"\"\"Randomly apply the desired func to the input image\"\"\"\n",
        "    return tf.cond(\n",
        "        tf.less(tf.random.uniform([], minval=0, maxval=1, dtype=tf.float32),\n",
        "                tf.cast(p, tf.float32)),\n",
        "        lambda: func(x),\n",
        "        lambda: x)\n",
        "\n",
        "@tf.function\n",
        "def custom_augment_train(image: tf.Tensor, label: tf.Tensor, gaussian_p: float = 0.1, solarize_p: float = 0.0) -> Tuple[tf.Tensor]:       \n",
        "    \"\"\"Container function to apply all custom augmentations\"\"\"\n",
        "    # Random flips\n",
        "    image = random_apply(tf.image.flip_left_right, image, p=0.5)\n",
        "    # Randomly apply transformation (color distortions) with probability p.\n",
        "    image = random_apply(color_jitter, image, p=0.8)\n",
        "    # Randomly apply grayscale\n",
        "    image = random_apply(color_drop, image, p=0.2)\n",
        "    # Randomly apply gausian blur\n",
        "    image = random_apply(gaussian_blur, image, p=gaussian_p)\n",
        "    # Randomly apply solarization\n",
        "    image = random_apply(solarize, image, p=solarize_p)\n",
        "\n",
        "    return (image, label)\n",
        "\n",
        "@tf.function\n",
        "def custom_augment_eval(image: tf.Tensor, label: tf.Tensor, crop_size:int = 224) -> Tuple[tf.Tensor]:\n",
        "    \"\"\"Randomly Resize and Augment Crops\"\"\"\n",
        "    # image resizing\n",
        "    image_shape = 260\n",
        "    image = tf.image.resize(image, (image_shape, image_shape))\n",
        "    # get the crop from the image\n",
        "    crop = tf.image.random_crop(image, (crop_size,crop_size,3))\n",
        "    resized_image = tf.image.resize(crop, (crop_size, crop_size))\n",
        "    return resized_image, label\n",
        "\n",
        "@tf.function\n",
        "def train_augmentations(image: tf.Tensor, label: tf.Tensor, gaussian_p: float = 0.1, solarize_p: float = 0.0, crop_size:int = 224) -> Tuple[tf.Tensor]:\n",
        "    \"\"\"Randomly Resize and Augment Crops\"\"\"\n",
        "    # scale the pixel values\n",
        "    image, label = scale_image(image , label)\n",
        "    # image resizing\n",
        "    image_shape = 260\n",
        "    image = tf.image.resize(image, (image_shape, image_shape))\n",
        "    # get the crop from the image\n",
        "    crop = tf.image.random_crop(image, (crop_size,crop_size,3))\n",
        "    crop_resize = tf.image.resize(crop, (crop_size, crop_size))\n",
        "    # color distortions\n",
        "    distored_image, label = custom_augment_train(crop_resize, label, gaussian_p)\n",
        "    return distored_image, label\n",
        "\n",
        "@tf.function\n",
        "def eval_augmentations(image: tf.Tensor, label: tf.Tensor) -> Tuple[tf.Tensor]:\n",
        "    \"\"\"Randomly Augment Images for Evaluation\"\"\"\n",
        "    # Scale the pixel values\n",
        "    image, label = scale_image(image , label)\n",
        "    # random horizontal flip\n",
        "    image = random_apply(tf.image.random_flip_left_right, image, p=0.5)\n",
        "    # Random resized crops\n",
        "    image, label = custom_augment_eval(image, label)\n",
        "\n",
        "    return image, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TyhdhWEfuoI"
      },
      "source": [
        "# üíø The Dataset\n",
        "\n",
        "---\n",
        "\n",
        "For the purposes of this example, we use the TF Flowers dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jbKVJJKvj21x"
      },
      "outputs": [],
      "source": [
        "tfds.disable_progress_bar()\n",
        "\n",
        "# Gather Flowers dataset\n",
        "train_ds, validation_ds = tfds.load(\n",
        "    \"tf_flowers\",\n",
        "    split=[\"train[:85%]\", \"train[85%:]\"],\n",
        "    as_supervised=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzaJxSEof6_M"
      },
      "source": [
        "## üññ Data Augmentation Pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ctHaiHHEPuVB"
      },
      "outputs": [],
      "source": [
        "# We create a Tuple because we have two loaders corresponding to each view\n",
        "trainloaders = tuple()\n",
        "\n",
        "for i in range(NUM_VIEWS):\n",
        "  trainloader = (\n",
        "      train_ds\n",
        "      .shuffle(1024)\n",
        "      .map(lambda x, y: train_augmentations(x, y, GAUSSIAN_P[i], SOLARIZE_P[i]), num_parallel_calls=AUTOTUNE)\n",
        "  )\n",
        "  trainloader = trainloader.with_options(options)\n",
        "  trainloaders+=(trainloader,)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8zt-j3Zf-la"
      },
      "source": [
        "## ‚öôÔ∏è Dataloader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJp3ViRVQCwS"
      },
      "outputs": [],
      "source": [
        "# zip both the dataloaders together\n",
        "trainloader = tf.data.Dataset.zip(trainloaders)\n",
        "\n",
        "# final trainloader to be used for training\n",
        "trainloader = (\n",
        "    trainloader\n",
        "    .batch(TRAIN_BATCH_SIZE * strategy.num_replicas_in_sync)\n",
        "    .map(shuffle_zipped_output, num_parallel_calls=AUTOTUNE)\n",
        "    .prefetch(AUTOTUNE)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQTV9RotiRCW"
      },
      "source": [
        "# ‚úçÔ∏è Model Architecture & Training\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IsyuaYYiTka"
      },
      "source": [
        "## üè† Building the network\n",
        "![](https://github.com/facebookresearch/vicreg/blob/main/.github/vicreg_archi_full.jpg?raw=true)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3yk3MH6ifAc"
      },
      "outputs": [],
      "source": [
        "class VICReg(tf.keras.Model):\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_units: int,\n",
        "        invar_coeff: float,\n",
        "        var_coeff: float,\n",
        "        cov_coeff: float,\n",
        "        **kwargs\n",
        "    ) -> None:\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        self.num_units = num_units\n",
        "        self.invar_coeff = invar_coeff\n",
        "        self.var_coeff = var_coeff\n",
        "        self.cov_coeff = cov_coeff\n",
        "\n",
        "        self.encoder = self.build_encoder()\n",
        "        self.expander = self.build_expander(self.num_units)\n",
        "\n",
        "        self.loss_tracker = tf.keras.metrics.Mean(name=\"vicreg_loss\")\n",
        "        self.invarloss_tracker = tf.keras.metrics.Mean(name=\"invariance_loss\")\n",
        "        self.varloss_tracker = tf.keras.metrics.Mean(name=\"variance_loss\")\n",
        "        self.covloss_tracker = tf.keras.metrics.Mean(name=\"covariance_loss\")\n",
        "\n",
        "    def get_config(self):\n",
        "        return {\n",
        "            \"invar_coeff\": self.invar_coeff,\n",
        "            \"var_coeff\": self.var_coeff,\n",
        "            \"cov_coeff\": self.cov_coeff,\n",
        "            \"num_units\": self.num_units,\n",
        "        }\n",
        "\n",
        "    @classmethod\n",
        "    def from_config(cls, config):\n",
        "        return cls(**config)\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [\n",
        "            self.loss_tracker,\n",
        "            self.invarloss_tracker,\n",
        "            self.varloss_tracker,\n",
        "            self.covloss_tracker,\n",
        "        ]\n",
        "\n",
        "    def build_encoder(self):\n",
        "        encoder_input = tf.keras.layers.Input((None, None, 3))\n",
        "        base_model = tf.keras.applications.ResNet50(\n",
        "            include_top=False, weights=None, input_shape=(None, None, 3)\n",
        "        )\n",
        "        base_model.trainable = True\n",
        "        representations = base_model(encoder_input, training=True)\n",
        "        encoder_output = tf.keras.layers.GlobalAveragePooling2D()(representations)\n",
        "        encoder = tf.keras.models.Model(\n",
        "            inputs=encoder_input, outputs=encoder_output, name=\"encoder\"\n",
        "        )\n",
        "        return encoder\n",
        "\n",
        "    def build_expander(self, num_units: int):\n",
        "        expander_input = tf.keras.layers.Input((2048,))\n",
        "\n",
        "        projection_1 = tf.keras.layers.Dense(num_units)(expander_input)\n",
        "        projection_1 = tf.keras.layers.BatchNormalization()(projection_1)\n",
        "        projection_1 = tf.keras.layers.Activation(\"relu\")(projection_1)\n",
        "\n",
        "        projection_2 = tf.keras.layers.Dense(num_units)(projection_1)\n",
        "        projection_2 = tf.keras.layers.BatchNormalization()(projection_2)\n",
        "        projection_2 = tf.keras.layers.Activation(\"relu\")(projection_2)\n",
        "\n",
        "        expander_output = tf.keras.layers.Dense(num_units)(projection_2)\n",
        "\n",
        "        expander = tf.keras.models.Model(\n",
        "            inputs=expander_input, outputs=expander_output, name=\"expander\"\n",
        "        )\n",
        "\n",
        "        return expander\n",
        "\n",
        "    def save_weights(self):\n",
        "        self.encoder.save_weights(\"encoder.h5\")\n",
        "        self.expander.save_weights(\"expander.h5\")\n",
        "\n",
        "    def train_step(self, images):\n",
        "        x, x_prime = images[0][0], images[1][0]\n",
        "        inputs = [x, x_prime]\n",
        "        batch_size = inputs[0][0].shape[0]\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Get Representations (through encoder)\n",
        "            y = self.encoder(x)\n",
        "            y_prime = self.encoder(x_prime)\n",
        "\n",
        "            # Get Embeddings (through expander)\n",
        "            z = self.expander(y)\n",
        "            z_prime = self.expander(y_prime)\n",
        "\n",
        "            # Calculate the Representation (Invariance) Loss\n",
        "            invar_loss = tf.keras.metrics.mean_squared_error(z, z_prime)\n",
        "\n",
        "            # Calculate var. and std. dev. of embeddings\n",
        "            z = z - tf.reduce_mean(z, axis=0)\n",
        "            z_prime = z_prime - tf.reduce_mean(z_prime, axis=0)\n",
        "            std_z = tf.sqrt(tf.math.reduce_variance(z, axis=0) + 0.0001)\n",
        "            std_z_prime = tf.sqrt(tf.math.reduce_variance(z_prime, axis=0) + 0.0001)\n",
        "\n",
        "            # Calculate the Variance Loss (Hinge Function)\n",
        "            var_loss = (\n",
        "                tf.reduce_mean(tf.nn.relu(1 - std_z)) / 2\n",
        "                + tf.reduce_mean(tf.nn.relu(1 - std_z_prime)) / 2\n",
        "            )\n",
        "\n",
        "            # Get Covariance Matrix\n",
        "            cov_z = (z.T @ z) / (batch_size - 1)\n",
        "            cov_z_prime = (z_prime.T @ z_prime) / (batch_size - 1)\n",
        "\n",
        "            # Calculate the Covariance Loss\n",
        "            cov_loss_z = tf.divide(tf.reduce_sum(tf.pow(off_diagonal(cov_z), 2)), 8192)\n",
        "            cov_loss_z_prime = tf.divide(\n",
        "                tf.reduce_sum(tf.pow(off_diagonal(cov_z_prime), 2)), 8192\n",
        "            )\n",
        "            cov_loss = cov_loss_z + cov_loss_z_prime\n",
        "\n",
        "            # Weighted Avg. of Invariance, Variance and Covariance Loss\n",
        "            loss = (\n",
        "                self.invar_coeff * invar_loss\n",
        "                + self.var_coeff * var_loss\n",
        "                + self.cov_coeff * cov_loss\n",
        "            )\n",
        "\n",
        "        # Compute gradients\n",
        "        variables = self.encoder.trainable_variables + self.expander.trainable_variables\n",
        "        gradients = tape.gradient(loss, variables)\n",
        "        # Update weights\n",
        "        self.optimizer.apply_gradients(zip(gradients, variables))\n",
        "        # Compute our own metrics\n",
        "        self.loss_tracker.update_state(loss)\n",
        "        self.invarloss_tracker.update_state(invar_loss)\n",
        "        self.varloss_tracker.update_state(var_loss)\n",
        "        self.covloss_tracker.update_state(cov_loss)\n",
        "        # Return a dict mapping metric names to current value\n",
        "        return {\n",
        "            \"loss\": self.loss_tracker.result(),\n",
        "            \"invariance_loss\": self.invarloss_tracker.result(),\n",
        "            \"variance_loss\": self.varloss_tracker.result(),\n",
        "            \"covariance_loss\": self.covloss_tracker.result(),\n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jX8kkEP59YB"
      },
      "source": [
        "## üèÉ Train !!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E5VIi6z3z3nU"
      },
      "outputs": [],
      "source": [
        "# The training protocol for VICReg follows those of BYOL and Barlow Twins,\n",
        "# i.e. the use of LARS which is adaptive algorithm meant for large batch training\n",
        "lr_decayed_fn = tf.keras.optimizers.schedules.CosineDecay(\n",
        "    initial_learning_rate=BASE_LR, decay_steps=DECAY_STEPS\n",
        ")\n",
        "opt = tfm.optimization.lars_optimizer.LARS(\n",
        "    learning_rate=lr_decayed_fn, weight_decay_rate=WEIGHT_DECAY\n",
        ")\n",
        "\n",
        "with strategy.scope():\n",
        "    model = VICReg(\n",
        "        num_units=MLP_UNITS,\n",
        "        invar_coeff=INVAR_COEFF,\n",
        "        var_coeff=VAR_COEFF,\n",
        "        cov_coeff=COV_COEFF,\n",
        "    )\n",
        "    model.compile(optimizer=opt)\n",
        "model.fit(trainloader, epochs=NUM_TRAINING_EPOCHS)\n",
        "model.save_weights()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üë®üèª‚Äç‚öñÔ∏è Linear Evaluation\n",
        "---\n",
        "We use a linear evaluation protocol i.e., we train a linear classifier on top of the frozen representations of the ResNet-50 backbone pretrained with VICReg. "
      ],
      "metadata": {
        "id": "TCFAidvYDhRr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚öôÔ∏è Dataloader for Linear Evaluation\n",
        "\n",
        "As detailed in Appendix C.2 Imagenet Evaluation, the training data augmentation pipeline is composed of random cropping\n",
        "and resize of ratio 0.2 to 1.0 with size 224 √ó 224, and random horizontal flips.  During evaluation the\n",
        "validation images are simply center cropped and resized to 224 √ó 224."
      ],
      "metadata": {
        "id": "QnyhdrqqHACO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# Gather Flowers dataset\n",
        "train_ds, validation_ds, test_ds = tfds.load(\n",
        "    \"tf_flowers\",\n",
        "    split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],\n",
        "    as_supervised=True\n",
        ")\n",
        "\n",
        "eval_trainloader = (\n",
        "\ttrain_ds\n",
        "\t.shuffle(1024)\n",
        "\t.map(eval_augmentations, num_parallel_calls=AUTOTUNE)\n",
        "\t.batch(EVAL_BATCH_SIZE)\n",
        "\t.prefetch(AUTOTUNE)\n",
        ")\n",
        "\n",
        "eval_valdataloader = (\n",
        "  validation_ds\n",
        "  .shuffle(1024)\n",
        "  .map(scale_image, num_parallel_calls=AUTOTUNE)\n",
        "  .map(custom_augment_eval, num_parallel_calls=AUTOTUNE)\n",
        "\t.batch(EVAL_BATCH_SIZE)\n",
        "\t.prefetch(AUTOTUNE)\n",
        ")\n",
        "\n",
        "eval_testdataloader = (\n",
        "  test_ds\n",
        "  .shuffle(1024)\n",
        "  .map(scale_image, num_parallel_calls=AUTOTUNE)\n",
        "  .map(custom_augment_eval, num_parallel_calls=AUTOTUNE)\n",
        "\t.batch(EVAL_BATCH_SIZE)\n",
        "\t.prefetch(AUTOTUNE)\n",
        ")"
      ],
      "metadata": {
        "id": "i5l90ijzE08B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üè† Building the network"
      ],
      "metadata": {
        "id": "RhG8KrHMHOVf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_linear_classifier() -> tf.keras.Model:\n",
        "    # input placeholder\n",
        "    inputs = tf.keras.layers.Input(shape=(224, 224, 3))\n",
        "    # get vicreg model architecture\n",
        "    base_model = VICReg(\n",
        "        num_units=MLP_UNITS,\n",
        "        invar_coeff=INVAR_COEFF,\n",
        "        var_coeff=VAR_COEFF,\n",
        "        cov_coeff=COV_COEFF,\n",
        "    )\n",
        "    feature_backbone = base_model.build_encoder()\n",
        "    # load trained weights\n",
        "    feature_backbone.load_weights(\"encoder.h5\")\n",
        "    feature_backbone.trainable = False\n",
        "    x = feature_backbone(inputs, training=False)\n",
        "    outputs = tf.keras.layers.Dense(10, activation=\"softmax\")(x)\n",
        "    linear_model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "    return linear_model"
      ],
      "metadata": {
        "id": "d3rhGXn6AjNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üèÉ Evaluation !!"
      ],
      "metadata": {
        "id": "IZ0C19ErHcP2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_decayed_fn = tf.keras.optimizers.schedules.CosineDecay(\n",
        "    initial_learning_rate=EVAL_LR, decay_steps=DECAY_STEPS\n",
        ")\n",
        "\n",
        "with strategy.scope():\n",
        "  evaluation_model = get_linear_classifier()\n",
        "  evaluation_model.compile(loss=\"sparse_categorical_crossentropy\", \n",
        "                           metrics=[\"acc\"],\n",
        "                           optimizer=tf.keras.optimizers.SGD(learning_rate=lr_decayed_fn, weight_decay = WEIGHT_DECAY))\n",
        "\n",
        "evaluation_model.summary()"
      ],
      "metadata": {
        "id": "0f84fiAKHULu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# callback for early stopping\n",
        "early_stopper = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=3, verbose=2, restore_best_weights=True)\n",
        "\n",
        "# train the model meant for evaluation\n",
        "evaluation_model.fit(eval_trainloader,\n",
        "                 validation_data=eval_valdataloader,\n",
        "                 epochs=NUM_EVAL_EPOCHS,\n",
        "                 callbacks=[early_stopper])"
      ],
      "metadata": {
        "id": "x_qLcQe-IFMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = evaluation_model.evaluate(eval_testdataloader)"
      ],
      "metadata": {
        "id": "04Z4u3J8KnE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation_model.save(\"linear_eval\")"
      ],
      "metadata": {
        "id": "jyyV2Dc6LkiG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}