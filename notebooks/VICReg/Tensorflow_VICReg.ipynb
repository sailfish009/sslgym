{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üì¶ Packages and Basic Setup\n",
        "---"
      ],
      "metadata": {
        "id": "q3k-vKd0c8Uk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QoNTJN31iTgb"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install -U rich tf-models-official\n",
        "\n",
        "import random\n",
        "import os\n",
        "import numpy as np\n",
        "from rich import print\n",
        "import tensorflow_models as tfm\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from rich.progress import track\n",
        "from tensorflow.python.ops.numpy_ops import np_config\n",
        "\n",
        "from typing import Callable, Tuple, Any, List\n",
        "\n",
        "# Experimental options\n",
        "options = tf.data.Options()\n",
        "options.experimental_optimization.noop_elimination = True\n",
        "options.experimental_optimization.apply_default_optimizations = True\n",
        "options.experimental_deterministic = False\n",
        "options.threading.max_intra_op_parallelism = 1\n",
        "np_config.enable_numpy_behavior()\n",
        "\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ‚öô Configuration\n",
        "GLOBAL_SEED = 42 #@param {type: \"number\"}\n",
        "NUM_VIEWS = 2 #@param {type: \"number\"}\n",
        "NUM_EPOCHS = 10 #@param {type: \"number\"}\n",
        "BATCH_SIZE = 16 #@param {type: \"number\"}\n",
        "INVAR_COEFF = 25.0 #@param {type: \"number\"}\n",
        "VAR_COEFF = 25.0 #@param {type: \"number\"}\n",
        "COV_COEFF = 1.0 #@param {type: \"number\"}\n",
        "DECAY_STEPS = 1000 #@param {type: \"number\"}\n",
        "WEIGHT_DECAY = 1e-6 #@param {type: \"number\"}\n",
        "BASE_LR = 0.2 #@param {type: \"number\"}\n",
        "\n",
        "\n",
        "\n",
        "# ============ Random Seed ============\n",
        "def seed_everything(seed = GLOBAL_SEED):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    tf.experimental.numpy.random.seed(seed)\n",
        "    # When running on the CuDNN backend, two further options must be set\n",
        "    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
        "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "    # Set a fixed value for the hash seed\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    print(f\"Random seed set as {seed}\")\n",
        "\n",
        "    \n",
        "seed_everything()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "cellView": "form",
        "id": "x0ak7lsXgKf5",
        "outputId": "a943a28d-cfcb-452f-aa96-b742b893289d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Random seed set as \u001b[1;36m42\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Random seed set as <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üÜò Utility Classes and Functions\n",
        "---"
      ],
      "metadata": {
        "id": "PNagRfSfdAmO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def off_diagonal(x: tf.Tensor) -> tf.Tensor:\n",
        "    n, m = x.shape[0], x.shape[1]\n",
        "    assert n == m, f\"Not a square tensor, dimensions found: {n} and {m}\"\n",
        "\n",
        "    flattened_tensor = tf.reshape(x, [-1])[:-1]\n",
        "    elements = tf.reshape(flattened_tensor, [n - 1, n + 1])[:, 1:]\n",
        "    return tf.reshape(elements, [-1])"
      ],
      "metadata": {
        "id": "B9o8vLp4w69C"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üññ Utilites for Data Augmentation"
      ],
      "metadata": {
        "id": "wGDPpTX_dCl1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GAUSSIAN_P = [1.0, 0.1]\n",
        "SOLARIZE_P = [0.0, 0.2]\n",
        "\n",
        "def shuffle_zipped_output(a: Any, b: Any) -> Tuple[Any]:\n",
        "    \"\"\"Shuffle the given inputs\"\"\"\n",
        "    listify = [a,b]\n",
        "    random.shuffle(listify)\n",
        "    return listify[0], listify[1]\n",
        "\n",
        "@tf.function\n",
        "def scale_image(image: tf.Tensor, label: tf.Tensor) -> Tuple[tf.Tensor]:\n",
        "    \"\"\"Convert all images to float32\"\"\"\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "    return (image, label)\n",
        "\n",
        "@tf.function\n",
        "def gaussian_blur(image: tf.Tensor, kernel_size:int=23, padding: str='SAME') -> tf.Tensor:\n",
        "    \"\"\"\n",
        "    Randomly apply Gaussian Blur to the input image\n",
        "    \n",
        "    Reference: https://github.com/google-research/simclr/blob/master/data_util.py\n",
        "    \"\"\"\n",
        "\n",
        "    sigma = tf.random.uniform((1,))* 1.9 + 0.1\n",
        "    radius = tf.cast(kernel_size / 2, tf.int32)\n",
        "    kernel_size = radius * 2 + 1\n",
        "    x = tf.cast(tf.range(-radius, radius + 1), tf.float32)\n",
        "    blur_filter = tf.exp(\n",
        "        -tf.pow(x, 2.0) / (2.0 * tf.pow(tf.cast(sigma, tf.float32), 2.0)))\n",
        "    blur_filter /= tf.reduce_sum(blur_filter)\n",
        "\n",
        "    # One vertical and one horizontal filter.\n",
        "    blur_v = tf.reshape(blur_filter, [kernel_size, 1, 1, 1])\n",
        "    blur_h = tf.reshape(blur_filter, [1, kernel_size, 1, 1])\n",
        "    num_channels = tf.shape(image)[-1]\n",
        "    blur_h = tf.tile(blur_h, [1, 1, num_channels, 1])\n",
        "    blur_v = tf.tile(blur_v, [1, 1, num_channels, 1])\n",
        "    expand_batch_dim = image.shape.ndims == 3\n",
        "    if expand_batch_dim:\n",
        "      image = tf.expand_dims(image, axis=0)\n",
        "    blurred = tf.nn.depthwise_conv2d(\n",
        "        image, blur_h, strides=[1, 1, 1, 1], padding=padding)\n",
        "    blurred = tf.nn.depthwise_conv2d(\n",
        "        blurred, blur_v, strides=[1, 1, 1, 1], padding=padding)\n",
        "    if expand_batch_dim:\n",
        "      blurred = tf.squeeze(blurred, axis=0)\n",
        "    return blurred\n",
        "\n",
        "@tf.function\n",
        "def color_jitter(image: tf.Tensor, s: float = 0.5) -> tf.Tensor:\n",
        "    \"\"\"Randomly apply Color Jittering to the input image\"\"\"\n",
        "    x = tf.image.random_brightness(image, max_delta=0.8*s)\n",
        "    x = tf.image.random_contrast(x, lower=1-0.8*s, upper=1+0.8*s)\n",
        "    x = tf.image.random_saturation(x, lower=1-0.8*s, upper=1+0.8*s)\n",
        "    x = tf.image.random_hue(x, max_delta=0.2*s)\n",
        "    x = tf.clip_by_value(x, 0, 1)\n",
        "    return x\n",
        "\n",
        "@tf.function\n",
        "def solarize(image: tf.Tensor, threshold: int = 128) -> tf.Tensor:\n",
        "    \"\"\"Solarize the input image\"\"\"\n",
        "    return tf.where(image < threshold, image, 255 - image)\n",
        "\n",
        "@tf.function\n",
        "def color_drop(image: tf.Tensor) -> tf.Tensor:\n",
        "    \"\"\"Randomly convert the input image to GrayScale\"\"\"\n",
        "    image = tf.image.rgb_to_grayscale(image)\n",
        "    image = tf.tile(image, [1, 1, 3])\n",
        "    return image\n",
        "\n",
        "@tf.function\n",
        "def random_apply(func: Callable, x: tf.Tensor, p: float) -> tf.Tensor:\n",
        "    \"\"\"Randomly apply the desired func to the input image\"\"\"\n",
        "    return tf.cond(\n",
        "        tf.less(tf.random.uniform([], minval=0, maxval=1, dtype=tf.float32),\n",
        "                tf.cast(p, tf.float32)),\n",
        "        lambda: func(x),\n",
        "        lambda: x)\n",
        "\n",
        "@tf.function\n",
        "def custom_augment(image: tf.Tensor, label: tf.Tensor, gaussian_p: float = 0.1, solarize_p: float = 0.0) -> Tuple[tf.Tensor]:       \n",
        "    \"\"\"Container function to apply all custom augmentations\"\"\"\n",
        "    # Random flips\n",
        "    image = random_apply(tf.image.flip_left_right, image, p=0.5)\n",
        "    # Randomly apply transformation (color distortions) with probability p.\n",
        "    image = random_apply(color_jitter, image, p=0.8)\n",
        "    # Randomly apply grayscale\n",
        "    image = random_apply(color_drop, image, p=0.2)\n",
        "    # Randomly apply gausian blur\n",
        "    image = random_apply(gaussian_blur, image, p=gaussian_p)\n",
        "    # Randomly apply solarization\n",
        "    image = random_apply(solarize, image, p=solarize_p)\n",
        "\n",
        "    return (image, label)\n",
        "\n",
        "@tf.function\n",
        "def random_resize_crop(image: tf.Tensor, label: tf.Tensor, gaussian_p: float = 0.1, solarize_p: float = 0.0, crop_size:int = 224) -> Tuple[tf.Tensor]:\n",
        "    \"\"\"Randomly Resize and Augment Crops\"\"\"\n",
        "    # scale the pixel values\n",
        "    image, label = scale_image(image , label)\n",
        "    # image resizing\n",
        "    image_shape = 260\n",
        "    image = tf.image.resize(image, (image_shape, image_shape))\n",
        "    # get the crop from the image\n",
        "    crop = tf.image.random_crop(image, (crop_size,crop_size,3))\n",
        "    crop_resize = tf.image.resize(crop, (crop_size, crop_size))\n",
        "    # color distortions\n",
        "    distored_image, label = custom_augment(crop_resize, label, gaussian_p)\n",
        "    return distored_image, label "
      ],
      "metadata": {
        "id": "zvPO2q_uj_f7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üíø The Dataset\n",
        "\n",
        "---\n",
        "\n",
        "For the purposes of this example, we use the TF Flowers dataset."
      ],
      "metadata": {
        "id": "-TyhdhWEfuoI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfds.disable_progress_bar()\n",
        "\n",
        "# Gather Flowers dataset\n",
        "train_ds, validation_ds = tfds.load(\n",
        "    \"tf_flowers\",\n",
        "    split=[\"train[:85%]\", \"train[85%:]\"],\n",
        "    as_supervised=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbKVJJKvj21x",
        "outputId": "2eb38670-923b-41f1-8bf1-c97bed7239b2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset 218.21 MiB (download: 218.21 MiB, generated: 221.83 MiB, total: 440.05 MiB) to ~/tensorflow_datasets/tf_flowers/3.0.1...\n",
            "Dataset tf_flowers downloaded and prepared to ~/tensorflow_datasets/tf_flowers/3.0.1. Subsequent calls will reuse this data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üññ Data Augmentation Pipeline\n"
      ],
      "metadata": {
        "id": "bzaJxSEof6_M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We create a Tuple because we have two loaders corresponding to each view\n",
        "trainloaders = tuple()\n",
        "\n",
        "for i in range(NUM_VIEWS):\n",
        "  trainloader = (\n",
        "      train_ds\n",
        "      .shuffle(1024)\n",
        "      .map(lambda x, y: random_resize_crop(x, y, GAUSSIAN_P[i], SOLARIZE_P[i]), num_parallel_calls=AUTOTUNE)\n",
        "  )\n",
        "  trainloader = trainloader.with_options(options)\n",
        "  trainloaders+=(trainloader,)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctHaiHHEPuVB",
        "outputId": "4ace0879-67d0-4be3-a00a-53057264245b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚öôÔ∏è Dataloader\n"
      ],
      "metadata": {
        "id": "-8zt-j3Zf-la"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# zip both the dataloaders together\n",
        "trainloader = tf.data.Dataset.zip(trainloaders)\n",
        "\n",
        "# final trainloader to be used for training\n",
        "trainloader = (\n",
        "    trainloader\n",
        "    .batch(BATCH_SIZE)\n",
        "    .map(shuffle_zipped_output, num_parallel_calls=AUTOTUNE)\n",
        "    .prefetch(AUTOTUNE)\n",
        ")"
      ],
      "metadata": {
        "id": "zJp3ViRVQCwS"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚úçÔ∏è Model Architecture & Training\n",
        "---"
      ],
      "metadata": {
        "id": "VQTV9RotiRCW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üè† Building the network\n",
        "![](https://github.com/facebookresearch/vicreg/blob/main/.github/vicreg_archi_full.jpg?raw=true)"
      ],
      "metadata": {
        "id": "3IsyuaYYiTka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class VICReg(tf.keras.Model):\n",
        "  def __init__(self, \n",
        "      num_units: int = 8192,\n",
        "      invar_coeff = INVAR_COEFF,\n",
        "      var_coeff = VAR_COEFF,\n",
        "      cov_coeff = COV_COEFF,**kwargs\n",
        "    ) -> None:\n",
        "    super().__init__(**kwargs)\n",
        "\n",
        "    self.num_units = num_units\n",
        "    self.invar_coeff = invar_coeff\n",
        "    self.var_coeff = var_coeff\n",
        "    self.cov_coeff = cov_coeff\n",
        "\n",
        "    self.encoder = self.build_encoder()\n",
        "    self.expander = self.build_expander(self.num_units)\n",
        "\n",
        "    self.loss_tracker = tf.keras.metrics.Mean(name=\"vicreg_loss\")\n",
        "\n",
        "  def get_config(self):\n",
        "    return {\"invar_coeff\": self.invar_coeff,\n",
        "            \"var_coeff\": self.var_coeff,\n",
        "            \"cov_coeff\": self.cov_coeff,\n",
        "            \"num_units\": self.num_units}\n",
        "\n",
        "  @classmethod\n",
        "  def from_config(cls, config):\n",
        "      return cls(**config)\n",
        "\n",
        "  @property\n",
        "  def metrics(self):\n",
        "      return [\n",
        "          self.loss_tracker,\n",
        "      ]\n",
        "\n",
        "  def build_encoder(self):\n",
        "    encoder_input = tf.keras.layers.Input((None, None, 3))\n",
        "    base_model = tf.keras.applications.ResNet50(include_top=False,\n",
        "      weights=None, input_shape=(None, None, 3))\n",
        "    base_model.trainable = True\n",
        "    representations = base_model(encoder_input, training=True)\n",
        "    encoder_output = tf.keras.layers.GlobalAveragePooling2D()(representations)\n",
        "    encoder = tf.keras.models.Model(inputs = encoder_input, outputs = encoder_output, name = \"encoder\")\n",
        "    return encoder\n",
        "\n",
        "  def build_expander(self, num_units: int):\n",
        "    expander_input = tf.keras.layers.Input((2048, ))\n",
        "\n",
        "    projection_1 = tf.keras.layers.Dense(num_units)(expander_input)\n",
        "    projection_1 = tf.keras.layers.BatchNormalization()(projection_1)\n",
        "    projection_1 = tf.keras.layers.Activation(\"relu\")(projection_1)\n",
        "\n",
        "    projection_2 = tf.keras.layers.Dense(num_units)(projection_1)\n",
        "    projection_2 = tf.keras.layers.BatchNormalization()(projection_2)\n",
        "    projection_2 = tf.keras.layers.Activation(\"relu\")(projection_2)\n",
        "\n",
        "    expander_output = tf.keras.layers.Dense(num_units)(projection_2)\n",
        "\n",
        "    expander = tf.keras.models.Model(inputs = expander_input, outputs = expander_output, name = \"expander\")\n",
        "\n",
        "    return expander\n",
        "\n",
        "  def train_step(self, images):\n",
        "    x, x_prime = images[0][0], images[1][0]\n",
        "    inputs = [x, x_prime]\n",
        "    batch_size = inputs[0][0].shape[0]\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "      # Get Representations (through encoder)\n",
        "      y = self.encoder(x)\n",
        "      y_prime = self.encoder(x_prime)\n",
        "\n",
        "      # Get Embeddings (through expander)\n",
        "      z = self.expander(y)\n",
        "      z_prime = self.expander(y_prime)\n",
        "\n",
        "       # Calculate the Representation (Invariance) Loss\n",
        "      invar_loss = tf.keras.metrics.mean_squared_error(z, z_prime)\n",
        "\n",
        "      # Calculate var. and std. dev. of embeddings\n",
        "      z = z - tf.reduce_mean(z, axis=0)\n",
        "      z_prime = z_prime - tf.reduce_mean(z_prime, axis=0)\n",
        "      std_z = tf.sqrt(tf.math.reduce_variance(z, axis = 0) + 0.0001)\n",
        "      std_z_prime = tf.sqrt(tf.math.reduce_variance(z_prime, axis = 0) + 0.0001)\n",
        "\n",
        "      # Calculate the Variance Loss (Hinge Function)\n",
        "      var_loss = tf.reduce_mean(tf.nn.relu(1 - std_z)) / 2 + tf.reduce_mean(tf.nn.relu(1 - std_z_prime)) / 2\n",
        "\n",
        "      # Get Covariance Matrix\n",
        "      cov_z = (z.T @ z) / (batch_size - 1)\n",
        "      cov_z_prime = (z_prime.T @ z_prime) / (batch_size - 1)\n",
        "\n",
        "       # Calculate the Covariance Loss\n",
        "      cov_loss_z = tf.divide(tf.reduce_sum(tf.pow(off_diagonal(cov_z), 2)), 8192)\n",
        "      cov_loss_z_prime = tf.divide(tf.reduce_sum(tf.pow(off_diagonal(cov_z_prime), 2)), 8192)\n",
        "      cov_loss = cov_loss_z + cov_loss_z_prime\n",
        "\n",
        "      # Weighted Avg. of Invariance, Variance and Covariance Loss\n",
        "      loss = (\n",
        "          self.invar_coeff * invar_loss\n",
        "          + self.var_coeff * var_loss\n",
        "          + self.cov_coeff * cov_loss\n",
        "      )\n",
        "\n",
        "    # Compute gradients\n",
        "    variables = self.encoder.trainable_variables + self.expander.trainable_variables\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "    # Update weights\n",
        "    self.optimizer.apply_gradients(zip(gradients, variables))\n",
        "    # Compute our own metrics\n",
        "    self.loss_tracker.update_state(loss)\n",
        "    # Return a dict mapping metric names to current value\n",
        "    return {\"loss\": self.loss_tracker.result()}"
      ],
      "metadata": {
        "id": "e3yk3MH6ifAc"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üèÉ Train !!"
      ],
      "metadata": {
        "id": "5jX8kkEP59YB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The training protocol for VICReg follows those of BYOL and Barlow Twins, \n",
        "# i.e. the use of LARS which is adaptive algorithm meant for large batch training\n",
        "lr_decayed_fn = tf.keras.optimizers.schedules.CosineDecay(\n",
        "    initial_learning_rate=BASE_LR, decay_steps=DECAY_STEPS)\n",
        "opt = tfm.optimization.lars_optimizer.LARS(learning_rate=lr_decayed_fn, weight_decay_rate = WEIGHT_DECAY)\n",
        "\n",
        "model = VICReg()\n",
        "model.compile(optimizer=opt)\n",
        "model.fit(trainloader, epochs = 3)"
      ],
      "metadata": {
        "id": "E5VIi6z3z3nU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}