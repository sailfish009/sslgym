{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "**Author:** [@SauravMaheshkar](https://twitter.com/MaheshkarSaurav)\n",
    "\n"
   ],
   "metadata": {
    "id": "WY5TB9IQymXR"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ðŸ“¦ Packages and Basic Setup\n",
    "---"
   ],
   "metadata": {
    "id": "2YF456yQy0Xd"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "edV1AuTdyOGm"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -U rich\n",
    "\n",
    "import gc\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "from typing import Sequence, Tuple, List, Iterable, Callable, Optional\n",
    "from PIL import ImageFilter, ImageOps\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from rich import print\n",
    "from rich.progress import track\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision import models as torchvision_models\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# @title âš™ Configuration\n",
    "random_seed = 42  # @param {type: \"number\"}\n",
    "epochs = 20  # @param {type: \"number\"}\n",
    "warmup_epochs = 5  # @param {type: \"number\"}\n",
    "start_warmup = 0.3  # @param {type: \"number\"}\n",
    "batch_size = 16  # @param {type: \"number\"}\n",
    "base_lr = 4.8  # @param {type: \"number\"}\n",
    "final_lr = 0.0048  # @param {type: \"number\"}\n",
    "weight_decay = 1e-6  # @param {type: \"number\"}\n",
    "hidden_mlp = 2048  # @param {type: \"number\"}\n",
    "feat_dim = 128  # @param {type: \"number\"}\n",
    "nmb_prototypes = 3000  # @param {type: \"number\"}\n",
    "epsilon = 0.05  # @param {type: \"number\"}\n",
    "temperature = 0.1  # @param {type: \"number\"}\n",
    "sinkhorn_iterations = 3  # @param {type: \"number\"}\n",
    "SIZE_CROPS = [224, 96]\n",
    "NMB_CROPS = [2, 6]\n",
    "MIN_SCALE_CROPS = [0.5, 0.14]\n",
    "MAX_SCALE_CROPS = [1.0, 0.5]\n",
    "CROPS_FOR_ASSIGN = [0, 1]\n",
    "\n",
    "\n",
    "# ============ Random Seed ... ==========\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "seed_everything(seed=random_seed)"
   ],
   "metadata": {
    "id": "UkxaZyqpy4iD"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ðŸ†˜ Utility Classes and Functions\n",
    "---"
   ],
   "metadata": {
    "id": "_TuHBZ75y54T"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ðŸ–– Utilites for Data Augmentation"
   ],
   "metadata": {
    "id": "Mwivtw9_y8Ib"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class GaussianBlur(object):\n",
    "    \"\"\"\n",
    "    Apply Gaussian Blur to the PIL image.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, p: float = 0.5, radius_min: float = 0.1, radius_max: float = 2.0\n",
    "    ) -> None:\n",
    "        self.prob = p\n",
    "        self.radius_min = radius_min\n",
    "        self.radius_max = radius_max\n",
    "\n",
    "    def __call__(self, img):\n",
    "        do_it = random.random() <= self.prob\n",
    "        if not do_it:\n",
    "            return img\n",
    "\n",
    "        return img.filter(\n",
    "            ImageFilter.GaussianBlur(\n",
    "                radius=random.uniform(self.radius_min, self.radius_max)\n",
    "            )\n",
    "        )"
   ],
   "metadata": {
    "id": "umsMer91zfMR"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## â›‘ï¸ Utility Functions"
   ],
   "metadata": {
    "id": "hiWX2nRYy9D2"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def get_color_distortion(strength: float = 1.0):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "      strength (float): strength of color distortion\n",
    "    \"\"\"\n",
    "    color_jitter = transforms.ColorJitter(\n",
    "        0.8 * strength, 0.8 * strength, 0.8 * strength, 0.2 * strength\n",
    "    )\n",
    "    rnd_color_jitter = transforms.RandomApply([color_jitter], p=0.8)\n",
    "    rnd_gray = transforms.RandomGrayscale(p=0.2)\n",
    "    color_distort = transforms.Compose([rnd_color_jitter, rnd_gray])\n",
    "    return color_distort\n",
    "\n",
    "\n",
    "def sinkhorn(Q, nmb_iters):\n",
    "    with torch.no_grad():\n",
    "        sum_Q = torch.sum(Q)\n",
    "        Q /= sum_Q\n",
    "\n",
    "        u = torch.zeros(Q.shape[0]).to(device)\n",
    "        r = torch.ones(Q.shape[0]).to(device) / Q.shape[0]\n",
    "        c = torch.ones(Q.shape[1]).to(device) / Q.shape[1]\n",
    "\n",
    "        curr_sum = torch.sum(Q, dim=1)\n",
    "\n",
    "        for it in range(nmb_iters):\n",
    "            u = curr_sum\n",
    "            Q *= (r / u).unsqueeze(1)\n",
    "            Q *= (c / torch.sum(Q, dim=0)).unsqueeze(0)\n",
    "            curr_sum = torch.sum(Q, dim=1)\n",
    "        return (Q / torch.sum(Q, dim=0, keepdim=True)).t().float()"
   ],
   "metadata": {
    "id": "Ut0dSE6JzjcV"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ðŸ’¿ The Dataset\n",
    "---\n",
    "\n",
    "For the purposes of this example, we use the CIFAR10 dataset."
   ],
   "metadata": {
    "id": "lKHYNT6RzAM7"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ðŸ–– Data Augmentation Pipeline"
   ],
   "metadata": {
    "id": "oPD2OJ9lzD8k"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class CIFARMultiCropDataset(datasets.CIFAR10):\n",
    "    \"\"\"\n",
    "    Custom MultiCrop Dataset for CIFAR10, could be ideally replaced with any dataset from torch\n",
    "\n",
    "    References:\n",
    "\n",
    "    * https://github.com/facebookresearch/swav/blob/main/src/multicropdataset.py\n",
    "    * https://github.com/abhinavagarwalla/swav-cifar10/blob/master/src/multicropdataset.py\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_path: str,\n",
    "        size_crops: Tuple[int, int],\n",
    "        nmb_crops: Tuple[int, int],\n",
    "        min_scale_crops: Tuple[float, float],\n",
    "        max_scale_crops: Tuple[float, float],\n",
    "        size_dataset=-1,\n",
    "    ):\n",
    "        # Download CIFAR10\n",
    "        super(CIFARMultiCropDataset, self).__init__(data_path, download=True)\n",
    "\n",
    "        # Sanity checks\n",
    "        assert len(size_crops) == len(nmb_crops)\n",
    "        assert len(min_scale_crops) == len(nmb_crops)\n",
    "        assert len(max_scale_crops) == len(nmb_crops)\n",
    "        if size_dataset >= 0:\n",
    "            self.samples = self.samples[:size_dataset]\n",
    "\n",
    "        color_transform = [get_color_distortion(), GaussianBlur()]\n",
    "        mean = [0.485, 0.456, 0.406]\n",
    "        std = [0.228, 0.224, 0.225]\n",
    "        trans = []\n",
    "        for i in range(len(size_crops)):\n",
    "            randomresizedcrop = transforms.RandomResizedCrop(\n",
    "                size_crops[i],\n",
    "                scale=(min_scale_crops[i], max_scale_crops[i]),\n",
    "            )\n",
    "            trans.extend(\n",
    "                [\n",
    "                    transforms.Compose(\n",
    "                        [\n",
    "                            randomresizedcrop,\n",
    "                            transforms.RandomHorizontalFlip(p=0.5),\n",
    "                            transforms.Compose(color_transform),\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize(mean=mean, std=std),\n",
    "                        ]\n",
    "                    )\n",
    "                ]\n",
    "                * nmb_crops[i]\n",
    "            )\n",
    "        self.trans = trans\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = self.data[index]\n",
    "        image = Image.fromarray(img)\n",
    "        multi_crops = list(map(lambda trans: trans(image), self.trans))\n",
    "        return multi_crops"
   ],
   "metadata": {
    "id": "qUJJe6oZ0Ew4"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## âš™ï¸ Dataloader\n"
   ],
   "metadata": {
    "id": "KOfqEg2IzG2q"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%%capture\n",
    "dataset = CIFARMultiCropDataset(\n",
    "    data_path=\"./data\",\n",
    "    size_crops=SIZE_CROPS,\n",
    "    nmb_crops=NMB_CROPS,\n",
    "    min_scale_crops=MIN_SCALE_CROPS,\n",
    "    max_scale_crops=MAX_SCALE_CROPS,\n",
    ")\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=2,\n",
    "    pin_memory=True,\n",
    "    drop_last=True,\n",
    ")"
   ],
   "metadata": {
    "id": "CGyUfVqJzJAl"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# âœï¸ Model Architecture & Training\n",
    "---"
   ],
   "metadata": {
    "id": "QoMlViwTzKEt"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Building the network\n",
    "\n",
    "![](https://i.ibb.co/TtSW4Fd/figure-3.png)\n",
    "\n",
    "We borrow this implementation from the [official implementation](https://github.com/facebookresearch/swav/blob/main/src/resnet50.py)"
   ],
   "metadata": {
    "id": "jKKSzlAozL4h"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(\n",
    "        in_planes,\n",
    "        out_planes,\n",
    "        kernel_size=3,\n",
    "        stride=stride,\n",
    "        padding=dilation,\n",
    "        groups=groups,\n",
    "        bias=False,\n",
    "        dilation=dilation,\n",
    "    )\n",
    "\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    __constants__ = [\"downsample\"]\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        inplanes,\n",
    "        planes,\n",
    "        stride=1,\n",
    "        downsample=None,\n",
    "        groups=1,\n",
    "        base_width=64,\n",
    "        dilation=1,\n",
    "        norm_layer=None,\n",
    "    ):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        if groups != 1 or base_width != 64:\n",
    "            raise ValueError(\"BasicBlock only supports groups=1 and base_width=64\")\n",
    "        if dilation > 1:\n",
    "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
    "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = norm_layer(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = norm_layer(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "    __constants__ = [\"downsample\"]\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        inplanes,\n",
    "        planes,\n",
    "        stride=1,\n",
    "        downsample=None,\n",
    "        groups=1,\n",
    "        base_width=64,\n",
    "        dilation=1,\n",
    "        norm_layer=None,\n",
    "    ):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        width = int(planes * (base_width / 64.0)) * groups\n",
    "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv1x1(inplanes, width)\n",
    "        self.bn1 = norm_layer(width)\n",
    "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
    "        self.bn2 = norm_layer(width)\n",
    "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
    "        self.bn3 = norm_layer(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        block,\n",
    "        layers,\n",
    "        zero_init_residual=False,\n",
    "        groups=1,\n",
    "        widen=1,\n",
    "        width_per_group=64,\n",
    "        replace_stride_with_dilation=None,\n",
    "        norm_layer=None,\n",
    "        normalize=False,\n",
    "        output_dim=0,\n",
    "        hidden_mlp=0,\n",
    "        nmb_prototypes=0,\n",
    "        eval_mode=False,\n",
    "    ):\n",
    "        super(ResNet, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "\n",
    "        self.eval_mode = eval_mode\n",
    "        self.padding = nn.ConstantPad2d(1, 0.0)\n",
    "\n",
    "        self.inplanes = width_per_group * widen\n",
    "        self.dilation = 1\n",
    "        if replace_stride_with_dilation is None:\n",
    "            # each element in the tuple indicates if we should replace\n",
    "            # the 2x2 stride with a dilated convolution instead\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\n",
    "                \"replace_stride_with_dilation should be None \"\n",
    "                \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation)\n",
    "            )\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "\n",
    "        # change padding 3 -> 2 compared to original torchvision code because added a padding layer\n",
    "        num_out_filters = width_per_group * widen\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            3, num_out_filters, kernel_size=7, stride=2, padding=2, bias=False\n",
    "        )\n",
    "        self.bn1 = norm_layer(num_out_filters)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, num_out_filters, layers[0])\n",
    "        num_out_filters *= 2\n",
    "        self.layer2 = self._make_layer(\n",
    "            block,\n",
    "            num_out_filters,\n",
    "            layers[1],\n",
    "            stride=2,\n",
    "            dilate=replace_stride_with_dilation[0],\n",
    "        )\n",
    "        num_out_filters *= 2\n",
    "        self.layer3 = self._make_layer(\n",
    "            block,\n",
    "            num_out_filters,\n",
    "            layers[2],\n",
    "            stride=2,\n",
    "            dilate=replace_stride_with_dilation[1],\n",
    "        )\n",
    "        num_out_filters *= 2\n",
    "        self.layer4 = self._make_layer(\n",
    "            block,\n",
    "            num_out_filters,\n",
    "            layers[3],\n",
    "            stride=2,\n",
    "            dilate=replace_stride_with_dilation[2],\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "        # normalize output features\n",
    "        self.l2norm = normalize\n",
    "\n",
    "        # projection head\n",
    "        if output_dim == 0:\n",
    "            self.projection_head = None\n",
    "        elif hidden_mlp == 0:\n",
    "            self.projection_head = nn.Linear(\n",
    "                num_out_filters * block.expansion, output_dim\n",
    "            )\n",
    "        else:\n",
    "            self.projection_head = nn.Sequential(\n",
    "                nn.Linear(num_out_filters * block.expansion, hidden_mlp),\n",
    "                nn.BatchNorm1d(hidden_mlp),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Linear(hidden_mlp, output_dim),\n",
    "            )\n",
    "\n",
    "        # prototype layer\n",
    "        self.prototypes = None\n",
    "        if isinstance(nmb_prototypes, list):\n",
    "            self.prototypes = MultiPrototypes(output_dim, nmb_prototypes)\n",
    "        elif nmb_prototypes > 0:\n",
    "            self.prototypes = nn.Linear(output_dim, nmb_prototypes, bias=False)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(\n",
    "            block(\n",
    "                self.inplanes,\n",
    "                planes,\n",
    "                stride,\n",
    "                downsample,\n",
    "                self.groups,\n",
    "                self.base_width,\n",
    "                previous_dilation,\n",
    "                norm_layer,\n",
    "            )\n",
    "        )\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(\n",
    "                block(\n",
    "                    self.inplanes,\n",
    "                    planes,\n",
    "                    groups=self.groups,\n",
    "                    base_width=self.base_width,\n",
    "                    dilation=self.dilation,\n",
    "                    norm_layer=norm_layer,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward_backbone(self, x):\n",
    "        x = self.padding(x)\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        if self.eval_mode:\n",
    "            return x\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward_head(self, x):\n",
    "        if self.projection_head is not None:\n",
    "            x = self.projection_head(x)\n",
    "\n",
    "        if self.l2norm:\n",
    "            x = nn.functional.normalize(x, dim=1, p=2)\n",
    "\n",
    "        if self.prototypes is not None:\n",
    "            return x, self.prototypes(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        if not isinstance(inputs, list):\n",
    "            inputs = [inputs]\n",
    "        idx_crops = torch.cumsum(\n",
    "            torch.unique_consecutive(\n",
    "                torch.tensor([inp.shape[-1] for inp in inputs]),\n",
    "                return_counts=True,\n",
    "            )[1],\n",
    "            0,\n",
    "        )\n",
    "        start_idx = 0\n",
    "        for end_idx in idx_crops:\n",
    "            _out = self.forward_backbone(\n",
    "                torch.cat(inputs[start_idx:end_idx]).cuda(non_blocking=True)\n",
    "            )\n",
    "            if start_idx == 0:\n",
    "                output = _out\n",
    "            else:\n",
    "                output = torch.cat((output, _out))\n",
    "            start_idx = end_idx\n",
    "        return self.forward_head(output)\n",
    "\n",
    "\n",
    "class MultiPrototypes(nn.Module):\n",
    "    def __init__(self, output_dim, nmb_prototypes):\n",
    "        super(MultiPrototypes, self).__init__()\n",
    "        self.nmb_heads = len(nmb_prototypes)\n",
    "        for i, k in enumerate(nmb_prototypes):\n",
    "            self.add_module(\"prototypes\" + str(i), nn.Linear(output_dim, k, bias=False))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = []\n",
    "        for i in range(self.nmb_heads):\n",
    "            out.append(getattr(self, \"prototypes\" + str(i))(x))\n",
    "        return out\n",
    "\n",
    "\n",
    "def resnet50(**kwargs):\n",
    "    return ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
    "\n",
    "\n",
    "model = resnet50(\n",
    "    normalize=True,\n",
    "    hidden_mlp=hidden_mlp,\n",
    "    output_dim=feat_dim,\n",
    "    nmb_prototypes=nmb_prototypes,\n",
    ").to(device)"
   ],
   "metadata": {
    "id": "0A1po4S64OTQ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {
    "id": "mjGpwvH7zWT0"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(), lr=base_lr, momentum=0.9, weight_decay=weight_decay\n",
    ")\n",
    "softmax = nn.Softmax(dim=1).cuda()\n",
    "\n",
    "print(\"Starting SwAV training !\")\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "for epoch in range(epochs):\n",
    "    for it, inputs in track(enumerate(data_loader), total=len(data_loader)):\n",
    "        # normalize the prototypes\n",
    "        with torch.no_grad():\n",
    "            w = model.prototypes.weight.data.clone()\n",
    "            w = nn.functional.normalize(w, dim=1, p=2)\n",
    "            model.prototypes.weight.copy_(w)\n",
    "\n",
    "        # ============ multi-res forward passes ... ============\n",
    "        embedding, output = model(inputs)\n",
    "        embedding = embedding.detach()\n",
    "        bs = inputs[0].size(0)\n",
    "\n",
    "        # ============ swav loss ... ============\n",
    "        loss = 0\n",
    "        for i, crop_id in enumerate(CROPS_FOR_ASSIGN):\n",
    "            with torch.no_grad():\n",
    "                out = output[bs * crop_id : bs * (crop_id + 1)]\n",
    "\n",
    "                # get assignments\n",
    "                q = torch.exp(out / epsilon).t()\n",
    "                q = sinkhorn(q, sinkhorn_iterations)[-bs:]\n",
    "\n",
    "            # cluster assignment prediction\n",
    "            subloss = 0\n",
    "            for v in np.delete(np.arange(np.sum(NMB_CROPS)), crop_id):\n",
    "                p = softmax(output[bs * v : bs * (v + 1)] / temperature)\n",
    "                subloss -= torch.mean(torch.sum(q * torch.log(p), dim=1))\n",
    "            loss += subloss / (np.sum(NMB_CROPS) - 1)\n",
    "        loss /= len(CROPS_FOR_ASSIGN)\n",
    "\n",
    "        # ============ backward and optim step ... ============\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # Garbage Collection\n",
    "        _ = gc.collect()\n",
    "\n",
    "    state = dict(\n",
    "        epoch=epoch + 1,\n",
    "        model=model.state_dict(),\n",
    "        optimizer=optimizer.state_dict(),\n",
    "    )\n",
    "    torch.save(state, \"./model.bin\")"
   ],
   "metadata": {
    "id": "qOi-l8C573tI"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
